{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Part 3","metadata":{}},{"cell_type":"markdown","source":"## Questions and Answers","metadata":{}},{"cell_type":"markdown","source":"1. Can we always use a random sample for a validation set? Why or why not?  <br />\nNo, in some cases it is not a good idea to use a random sample for the validation set. In time series forecasting for example it is not a good idea because taking out some random points for the validation set makes a trend incomplete. In this case, it would be better to cut out multiple a connected series of data points as validation set.\n\n2. What is overfitting? Provide an example.  <br />\nThe model performs very well on the training set but very poorly on the validation set. It has not learned but memorized. As an example one could imagine that there is an overfitting model that can decide whether an image was taken during the day or the night. If one would input an image from the training set it is very likely that the image is classified correctly. However, if one would input a random image e.g. from google image search, that was not part of the training set, it is very likely that the image is classified wrongly.\n\n3. What is a metric? How does it differ from \"loss\"?  <br />\nA metric is used to rate the performance of a model. The loss-function is used within training to determine how well the choosen parameters are. The goal of the algorithms is to minimize the loss-function. Metrics are used by humans while the loss-function is used by computers.\n\n4. How can pretrained models help?  <br />\nA pretrained model is a model that was trained using a large dataset. It can be used to solve similar problems using transfer learning. Using a pretrained model decreases the time needed to train the adjusted model.\n\n5. What is the \"head\" of a model?  <br />\n\"The Head is an analogy in machine learning thatâ€™s used to represent the output layer of an artificial neural network. It interprets the model as a backbone plus a head where the backbone refers to the architecture of the model and the head refers to the final layer of the architecture. It also interprets transfer learning as replacing the head of a pretrained backbone.\" [Source](https://codeburst.io/fast-ai-course-chapter-1-q-a-on-wsl2-22e0478e9f70#9b22)\n\n6. What kinds of features do the early layers of a CNN find? How about the later layers?  <br />\nThe early layers of a CNN find basic structures like colors or lines. The later layers use this basic structures to detect more advanced structures like for example rectangles.\n\n7. Are image models only useful for photos?  <br />\nNo, many things like for example sound can be converted into an image.  \n\n8. What is an \"architecture\"?  <br />\nA template of the model that we're trying to fit. The actual mathematical function that we're passing the input data and parameters to.\n\n9. What is a segmentation?  <br />\nSegmentation is the process of partitioning the image into different objects. For example the result of a segmentation could be that in an image containing a car and a house, the car is marked as car and the house is marked as house.\n","metadata":{}},{"cell_type":"markdown","source":"## Lessons Learned","metadata":{}},{"cell_type":"markdown","source":"### Jupyter Notebook\nI did not know that it is possible to use Jupyter Notebooks to write a Blog. I also was suprised that Jupyter Notebooks are serialized as JSON. Getting familiar with Google Colab was a bit frustrating at the beginning. Nevertheless I think it is a useful tool to test machine learning libraries in a fast way because many libraries are already preinstalled.\n\n### Deep Learning\nI already knew that Deep Learning Models are blackboxes, but I didn't know that there is a variety of tools (Lime, SHAP) that make it possible to (more or less) comprehend how a Deep Learning Model came to a certain conclusion.","metadata":{}}]}